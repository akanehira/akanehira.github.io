<html>
  <head>
    <link href='http://fonts.googleapis.com/css?family=Roboto:900,300,700,400|Raleway:700,400,300' rel='stylesheet' type='text/css'>
    <link href='http://necolas.github.io/normalize.css/3.0.2/normalize.css' rel="stylesheet">
    <link href='http://code.ionicframework.com/ionicons/1.5.2/css/ionicons.min.css' rel="stylesheet">
    <link rel="stylesheet" href="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
    <link href='stylesheets/animate.css' rel='stylesheet' type='text/css'>
    <link href='stylesheets/stagger.css' rel='stylesheet' type='text/css'>
    <link href='stylesheets/style.css' rel='stylesheet' type='text/css'>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no">
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-76546486-1', 'auto');
      ga('send', 'pageview');
</script>
  </head>
  <body>
    <!-- <h3 class="only-small">Show when it's small!</h3> -->
    <div class="container">
      <div class="col-md-12">
        <div class="col-md-8"><!-- Name -->
          <h1 class="my-name animated fadeInDown _1">Atsushi Kanehira</h1>
          <h4 class="my-credentials animated fadeInUp _2"><a href="http://www.mi.t.u-tokyo.ac.jp/en/">Machine Intelligence Laboratory</a>, The University of Tokyo</h4>
        </div>
        <div class="col-md-4"><!-- Contact Info -->
          <div class="contact animated fadeInDown _3">
            <div class="phone-number">
              <span class="icon ion-ios7-telephone"></span>
            </div>
            <div>
              <span class="icon ion-ios7-email"></span>
              <a class="email-address" href="mailto: kanehira@mi.t.u-tokyo.ac.jp">
              kanehira[at]mi.t.u-tokyo.ac.jp
              </a>
            </div>
          </div>
        </div><!-- end of Contact Info col-md-4 -->
      </div><!-- col-md-12 -->
    </div><!-- container -->

    <div class="container"><!-- Contact Info -->
      <div class="col-md-12">
        <div class="col-md-8">
          <!-- Credentials -->
          <div class="resume-content animated fadeIn _4">
            <h2 class="section-header">Education</h2>
            <ul>
              <li>
                <strong>Information Science and Technology, The University of Tokyo</strong>
                <div class="only-big">
                  <div>Ph.D., Mar. 2019</div>
                </div>
              </li>
              <li>
                <strong>Information Science and Technology, The University of Tokyo</strong>
                <div class="only-big">
                  <div>Master, Mar. 2016</div>
                </div>
              </li>
              <li>
                <strong>Mechano-Infomatics, The University of Tokyo</strong>
                <div class="only-big">
                  <div>Bachelor, Mar. 2014</div>
                </div>
              </li>
            </ul>
          </div><!-- End of Credentials -->

          <div class="animated fadeIn _6">
            <h2 class="section-header">Experience</h2>
            <ul>
              <li><strong>Visiting Researcher at <a href="http://www.vision.ee.ethz.ch/en/">Computer Vision Laboratory</a>, ETH Zurich</strong>
                <div class="only-big">
                  <div>Zurich, Sep. 2016- Feb. 2017</div>
                </div>
              </li>
              <li><strong>Intern at Microsoft Research Asia</strong>
                <div class="only-big">
                  <div>Beijing, Apr. 2017- July. 2017</div>
                </div>
              </li>
            </ul>
            <!-- <h2 class="section-header">Preprint</h2> -->
            <!-- <ul> -->
            <!--   <li> -->
            <!--     <strong>Multimodal Explanations by Predicting Counterfactuality in Videos.</strong> -->
            <!--     <div><u>Atsushi Kanehira</u>, Kentaro Takemoto, Sho Inayoshi, and Tatsuya Harada</div> -->
            <!--     <div><a href="./papers/counter.pdf">[paper]</a> <a href="./papers/counter_supp.pdf">[supp]</a> <a href="https://arxiv.org/abs/1812.01263">[arXiv]</a> </div> -->
            <!--   </li> -->
            <!--   <li> -->
            <!--     <strong>Learning to Explain with Complemental Examples.</strong> -->
            <!--     <div><u>Atsushi Kanehira</u> and Tatsuya Harada</div> -->
            <!--     <div><a href="./papers/with_example.pdf">[paper]</a> <a href="./papers/with_example_supp.pdf">[supp]</a> <a href="https://arxiv.org/abs/1812.01280">[arXiv]</a></div> -->
            <!--   </li> -->
            <!-- </ul> -->
            <h2 class="section-header">Publications</h2>
            <ul>
              <li>
<strong>Multimodal Explanations by Predicting Counterfactuality in Videos.</strong>
                <div><u>Atsushi Kanehira</u>, Kentaro Takemoto, Sho Inayoshi, and Tatsuya Harada</div>
		<div>CVPR 2019 (Oral / acceptance rate: 5.6%)</div>
                <div><a href="./papers/counter.pdf">[paper]</a> <a href="./papers/counter_supp.pdf">[supp]</a> <a href="https://arxiv.org/abs/1812.01263">[arXiv]</a> </div>
              </li>
              <li>
                <strong>Learning to Explain with Complemental Examples.</strong>
                <div><u>Atsushi Kanehira</u> and Tatsuya Harada</div>
		<div>CVPR 2019 (Oral / acceptance rate: 5.6%)</div>
                <div><a href="./papers/with_example.pdf">[paper]</a> <a href="./papers/with_example_supp.pdf">[supp]</a> <a href="https://arxiv.org/abs/1812.01280">[arXiv]</a></div>
              </li>
	      <li>
                <strong><i>Viewpoint</i>-aware Video Summarization.</strong>
                <div><u>Atsushi Kanehira</u>, Luc Van Gool, Yoshitaka Ushiku,  and Tatsuya Harada</div>
                <div>CVPR 2018 (Spotlight Oral / acceptance rate: 7.4%) </div>
		<div><a href="./papers/viewpoint.pdf">[paper]</a> <a href="./papers/viewpoint_supp.pdf">[supp]</a> <a href="https://arxiv.org/abs/1804.02843">[arXiv]</a> <a href="./viewpoint/VSUM.tar.gz">[dataset]</a>* <a href="./papers/cvpr18_poster_kanehira.pdf">[poster]</a></div>
		<div><h4><small>*(Only YouTube ID are included in the dataset. If you need raw videos, please contact me)</small></h4></div>
              </li>
              <li>
                <strong>Multi-label Ranking from Positive and Unlabeled Data.</strong>
                <div><u>Atsushi Kanehira</u> and Tatsuya Harada</div>
                <div>CVPR 2016 (Poster / acceptance rate: 29.9%)</div>
		<div> <a href="./papers/multiPU.pdf">[paper]</a> <a href="./papers/multiPU_supp.pdf">[supp]</a> <a href="./papers/cvpr16_poster_kanehira.pdf">[poster]</a></div>
              </li>
              <li>
                <strong>Recognizing Activities of Daily Living with a Wrist-mounted Camera.</strong>
                <div>Katsunori Ohnishi, <u>Atsushi Kanehira</u>, Asako Kanezaki, and Tatsuya Harada</div>
                <div>CVPR 2016 (Spotlight Oral / acceptance rate: 9.7%)</div>
		<div><a href="./papers/ADLwrist.pdf">[paper]</a> <a href="./papers/ADLwrist-supp.pdf">[supplemental]</a> <a href="./papers/cvpr16_poster_ohnishi.pdf">[poster]</a> <a href="http://www.mi.t.u-tokyo.ac.jp/static/projects/miladl/">[dataset]</a></div>
              </li>
              <li>
                <strong>True-negative Label Selection for Large-scale Multi-label Learning.</strong>
                <div><u>Atsushi Kanehira</u>, Andrew Shin, and Tatsuya Harada</div>
                <div>ICPR 2016 (Poster / acceptance rate: 55%)</div>
		<div><a href="./papers/cancun.pdf">[paper]</a></div>
              </li>
              </li>
            </ul>
            <h2 class="section-header">Competitions</h2>
            <ul>
              <li>
                <strong>ImageNet Large Scale Visual Recognition Challenge 2014 the 4th place in the task 2a: Classification+localization with provided training data</strong>
                <div>in conjunction with ECCV 2014 (invited oral), Senthil Purushwalkam, Yuichiro Tsuchiya, <u>Atsushi Kanehira</u>, Asako Kanezaki, and Tatsuya Harada</div>
                <div><a href="http://www.image-net.org/challenges/LSVRC/2014/"><i>http://www.image-net.org/challenges/LSVRC/2014/</i></a></div>
              </li>
              <li>
                <strong>ImageCLEF 2014 the 2nd place in the task : Scalable Concept Image Annotation</strong>
                <div>in conjunction with CLEF 2014, <u>Atsushi Kanehira</u>, Masatoshi Hidaka, Yusuke Mukuta,  Yuichiro Tsushiya, Tetsuaki Mano, and Tatsuya Harada</div>
                <div><a href="http://www.imageclef.org/2014"><i>http://www.imageclef.org/2014</i></a></div>
              </li>
            </ul>
            <h2 class="section-header">Projects</h2>
            <ul>
              <li>
                <strong>MILJS : Brand New JavaScript Libraries for Matrix Calculation and Machine Learning</strong>
                <div>Ken Miura, Tetsuaki Mano, <u>Atsushi Kanehira</u>, Yuichiro Tsuchiya, Tatsuya Harada</div>
                <div><a href="https://mil-tokyo.github.io/miljs.html"><i>https://mil-tokyo.github.io/miljs.html</i></a></div>
              </li>
            </ul>
            <h2 class="section-header">Invited Talks</h2>
            <ul>
              <li>
                <strong>Multi-label Ranking from Positive and Unlabeled Data.</strong>
                <div><u>Atsushi Kanehira</u>, and Tatsuya Harada</div>
                <div>MIRU 2016 (domestic) <a href="./papers/miru2016-slide-kanehira.pdf">[slide]</a></div>
              </li>
              <li>
                <strong>Recognizing Activities of Daily Living with a Wrist-mounted Camera.</strong>
                <div>Katsunori Ohnishi, <u>Atsushi Kanehira</u>, Asako Kanezaki, and Tatsuya Harada</div>
                <div>MIRU 2016 (domestic) <a href="./papers/miru2016-slide-ohnishi.pdf">[slide]</a></div>
              </li>
            </ul>
</div><!--  -->
        </div><!-- col-md-8 -->

        <!-- Skills Column -->
        <div class="col-md-4 animated fadeIn _5">
          <h2 class="section-header">Skills</h2>
          <ul>
            <li>Python</li>
            <li>C / C++</li>
            <li>JavaScript</li>
            <li>etc..</li>
          </ul>
        </div><!-- End of Skills -->
      </div><!-- End of Resume Content -->
      <div class="col-md-12">
        <p class="text-muted footer animated fadeInUp _6">Copyright &copy; Atsushi Kanehira 2016</p>
      </div>
    </div><!-- End of Container -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
    <script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
  </body>
</html>
